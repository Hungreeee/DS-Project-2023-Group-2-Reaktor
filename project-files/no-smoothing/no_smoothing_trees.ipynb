{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/samples/tree_data_sample.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_url = \"https://api.laji.fi/v0\"\n",
    "email = \"nghi.vodong942003@gmail.com\"\n",
    "access_token = \"PNQaOkSdHzJYm3zJI8PUG7OWHnmiILIOEakXPZ95gfoMEgICaGJ22IB5Hyfi5ZCT\"\n",
    "\n",
    "def extract_last_page (root_url, token, page_size):\n",
    "    response = requests.get(\n",
    "    url = root_url + '/warehouse/query/unit/list',\n",
    "    params={\n",
    "        'access_token': token,\n",
    "        'page': 1,\n",
    "        'pageSize': page_size, # Limit 10,000 per page\n",
    "        'informalTaxonGroupId': 'MVL.1083', # {Vascular plants: {Plant life forms: {Trees; Evergreen trees} } }\n",
    "        'orderBy': ['gathering.eventDate.begin DESC', 'document.loadDate DESC', 'unit.taxonVerbatim ASC'] # Default sorting\n",
    "    })\n",
    "\n",
    "    responseContent = response.content\n",
    "    results = json.loads(responseContent.decode('utf-8'))\n",
    "    lastPage = results['lastPage']\n",
    "    return lastPage\n",
    "\n",
    "lastPage = extract_last_page(root_url, access_token, 10000)\n",
    "\n",
    "features = [\n",
    "    \"gathering.displayDateTime\",\n",
    "    \"gathering.conversions.wgs84CenterPoint.lat\",\n",
    "    \"gathering.conversions.wgs84CenterPoint.lon\",\n",
    "    \"unit.linkings.taxon.id\",\n",
    "    \"unit.linkings.taxon.scientificName\",\n",
    "    \"gathering.interpretations.municipalityDisplayname\",\n",
    "    \"gathering.interpretations.finnishMunicipality\"\n",
    "]\n",
    "\n",
    "def extract_dataset (root_url, token, page_size, lastPage, features = []):\n",
    "    df = pd.DataFrame({ feature: [] for feature in features })\n",
    "    for pageIndex in range(1, lastPage + 1):\n",
    "    # Request data from API and go through all the pages in the loop (approximately 8m with 12 pages and 115739 rows)\n",
    "        response = requests.get(\n",
    "            url = root_url + '/warehouse/query/unit/list',\n",
    "            params={\n",
    "                'access_token': token,\n",
    "                'page': pageIndex,\n",
    "                'pageSize': page_size, # Limit 10,000 per page\n",
    "                'informalTaxonGroupId': 'MVL.1083', # {Vascular plants: {Plant life forms: {Trees; Evergreen trees} } }\n",
    "                'selected': features,\n",
    "                'orderBy': ['gathering.eventDate.begin DESC', 'document.loadDate DESC', 'unit.taxonVerbatim ASC'] # Default sorting\n",
    "        })\n",
    "\n",
    "        responseContent = response.content\n",
    "        dataset = json.loads(responseContent.decode('utf-8'))['results']\n",
    "        df = pd.concat([df, pd.json_normalize(dataset)])\n",
    "    return df\n",
    "\n",
    "df = extract_dataset(root_url, access_token, 10000, lastPage , features)\n",
    "df = df.rename(columns = {\n",
    "    \"gathering.displayDateTime\" : \"datetime\",\n",
    "    \"gathering.conversions.wgs84CenterPoint.lat\" : \"lat\",\n",
    "    \"gathering.conversions.wgs84CenterPoint.lon\": \"lon\",\n",
    "    \"gathering.interpretations.municipalityDisplayname\": \"municipality\",\n",
    "    \"gathering.interpretations.finnishMunicipality\" : \"municipalityId\",\n",
    "    \"unit.linkings.taxon.id\" : \"taxonId\",\n",
    "    \"unit.linkings.taxon.scientificName\" : \"scientificName\"})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_observations (dataframe, columns):\n",
    "    grouped_df = dataframe.groupby(columns).count()\n",
    "    grouped_df.reset_index(inplace = True)\n",
    "    columns_to_drop = list(filter(lambda name : name not in columns, grouped_df.columns))\n",
    "    grouped_df = grouped_df.drop(columns = columns_to_drop[1:])\n",
    "    grouped_df.columns = columns + [\"nof_obs\"]\n",
    "    return grouped_df\n",
    "\n",
    "# scientificName or taxonId works\n",
    "grouped_df = group_observations(df, ['municipalityId', 'scientificName'])\n",
    "#grouped_df.to_csv('grouped_municipality.csv')\n",
    "\n",
    "def pivot_obs_dataframe (dataframe, species_identifier, area_id):\n",
    "    pivoted_df = dataframe.pivot(index = area_id, columns = species_identifier, values = \"nof_obs\")\n",
    "    pivoted_df = pivoted_df.fillna(0.0)\n",
    "    return pivoted_df\n",
    "\n",
    "\n",
    "pivoted_df = pivot_obs_dataframe(grouped_df, \"scientificName\", \"municipalityId\")\n",
    "#pivoted_df.to_csv('pivoted_municipality.csv')\n",
    "pivoted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shannon_entropy (area_row):\n",
    "    numpy_row = area_row.to_numpy()\n",
    "    probabilities = numpy_row / np.sum(numpy_row)\n",
    "    probabilities = probabilities[np.where(probabilities > 0)]\n",
    "    return -np.sum(probabilities*np.log2(probabilities))\n",
    "\n",
    "shannon_entropies = pivoted_df.apply(shannon_entropy, axis=1)\n",
    "shannon_entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpson_index (area_row):\n",
    "    numpy_row = area_row.to_numpy()\n",
    "    observed_species = numpy_row[np.where(numpy_row > 0.0)]\n",
    "    species_index = observed_species * (observed_species - 1)\n",
    "    total_observations = np.sum(observed_species)\n",
    "    total_index = total_observations * (total_observations - 1)\n",
    "    return 1 - (np.sum(species_index) / total_index)\n",
    "\n",
    "simpson_indices = pivoted_df.apply(simpson_index, axis=1)\n",
    "simpson_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_url = \"https://api.laji.fi/v0\"\n",
    "email = \"nghi.vodong942003@gmail.com\"\n",
    "access_token = \"PNQaOkSdHzJYm3zJI8PUG7OWHnmiILIOEakXPZ95gfoMEgICaGJ22IB5Hyfi5ZCT\"\n",
    "\n",
    "def request_areas_info (municipality_ids, root_url, token):\n",
    "    assert len(municipality_ids) > 0\n",
    "    cleaned_ids = [id for id in municipality_ids if str(id) != \"nan\"]\n",
    "    unique_ids = list(set(cleaned_ids))\n",
    "    unique_ids.sort()\n",
    "    area_endpoint_url = root_url + \"/areas\"\n",
    "    ids_string = \"\"\n",
    "    nof_ids = len(unique_ids)\n",
    "    intervals = 1.0 * len(unique_ids) / 10\n",
    "    current_interval = 0\n",
    "    dataset = []\n",
    "    while current_interval < intervals:\n",
    "        ids_string = \"\"\n",
    "        ids_slice = unique_ids[current_interval*10 : min(current_interval*10 + 10, nof_ids)]\n",
    "        for municipality_id in ids_slice:\n",
    "            ids_string += \",\" + municipality_id\n",
    "        ids_string = ids_string[1:]\n",
    "        response = requests.get(\n",
    "            url = area_endpoint_url,\n",
    "            params={\n",
    "                'access_token': token,\n",
    "                'page': 1,\n",
    "                'pageSize': 10,\n",
    "                'idIn' : ids_string,\n",
    "        })\n",
    "        dataset.extend(json.loads(response.content.decode('utf-8'))['results'])\n",
    "        current_interval += 1\n",
    "    df = pd.json_normalize(dataset)\n",
    "    df.rename({'id' : 'municipalityId'}, inplace = True)\n",
    "    return df\n",
    "municipality_info_df = request_areas_info (\n",
    "    list(df[\"municipalityId\"]), root_url, access_token\n",
    ")\n",
    "municipality_info_df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
