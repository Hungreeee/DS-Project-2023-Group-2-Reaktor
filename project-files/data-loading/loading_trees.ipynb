{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import comb\n",
    "import scipy.misc\n",
    "scipy.misc.comb = comb\n",
    "from ecopy import diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API endpoint\n",
    "URL = 'https://api.laji.fi/v0'\n",
    "# Your email\n",
    "EMAIL = 'hungmguyen13102003@gmail.com'\n",
    "# Token ID\n",
    "TOKEN = 'ffaOqj71Ro1sqR0QAVYkmOFY6vG0qDtS0ESEjvanTgsihNq69zLNMgwjIelO0zmd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to request a token\n",
    "# Just query a POST with your email. You will get the token in an email they sent you.\n",
    "response = requests.post(\n",
    "  url = URL + '/api-users',\n",
    "  data = {\n",
    "    'email': EMAIL\n",
    "  })\n",
    "\n",
    "# Check if it has been registered to the site\n",
    "responseContent = json.loads(response.content.decode('utf-8'))\n",
    "responseContent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial request to get the last page\n",
    "response = requests.get(\n",
    "  url = URL + '/warehouse/query/unit/list',\n",
    "  params={\n",
    "    'access_token': TOKEN,\n",
    "    'page': 1,\n",
    "    'pageSize': 10000, # Limit 10,000 per page\n",
    "    'informalTaxonGroupId': 'MVL.1083', # {Vascular plants: {Plant life forms: {Trees; Evergreen trees} } }\n",
    "    'orderBy': ['gathering.eventDate.begin DESC', 'document.loadDate DESC', 'unit.taxonVerbatim ASC'] # Default sorting\n",
    "  })\n",
    "\n",
    "responseContent = response.content\n",
    "results = json.loads(responseContent.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastPage = results['lastPage']\n",
    "\n",
    "# Lists of variables\n",
    "date = []\n",
    "latitude = []\n",
    "longitude = []\n",
    "municipality = []\n",
    "taxonId = []\n",
    "science = []\n",
    "verbatim = []\n",
    "\n",
    "for pageIndex in range(1, lastPage + 1):\n",
    "    # Request data from API and go through all the pages in the loop (approximately 8m with 12 pages and 115739 rows)\n",
    "    response = requests.get(\n",
    "        url = URL + '/warehouse/query/unit/list',\n",
    "        params={\n",
    "            'access_token': TOKEN,\n",
    "            'page': pageIndex,\n",
    "            'pageSize': 10000, # Limit 10,000 per page\n",
    "            'informalTaxonGroupId': 'MVL.1083', # {Vascular plants: {Plant life forms: {Trees; Evergreen trees} } }\n",
    "            'orderBy': ['gathering.eventDate.begin DESC', 'document.loadDate DESC', 'unit.taxonVerbatim ASC'] # Default sorting\n",
    "    })\n",
    "\n",
    "    responseContent = response.content\n",
    "    dataset = json.loads(responseContent.decode('utf-8'))['results']\n",
    "\n",
    "    # Extract relevant information, sometimes they might be missing\n",
    "    for x in dataset:\n",
    "        # Date of collection; normally it would be \"DD-MM-YYYY\", sometimes it could be a range \"DD-MM-YYY - DD-MM-YYYY\"\n",
    "        if 'displayDateTime' in x['gathering']:\n",
    "            date.append(x['gathering']['displayDateTime'])\n",
    "        else:\n",
    "            date.append(None)\n",
    "\n",
    "        # Latitude and Longitude\n",
    "        if 'conversions' in x['gathering']:\n",
    "            latitude.append(x['gathering']['conversions']['wgs84CenterPoint']['lat'])\n",
    "            longitude.append(x['gathering']['conversions']['wgs84CenterPoint']['lon'])\n",
    "        else:\n",
    "            latitude.append(None)\n",
    "            longitude.append(None)\n",
    "\n",
    "        # Municipality\n",
    "        if 'interpretations' in x['gathering']  and 'municipalityDisplayname' in x['gathering']['interpretations']:\n",
    "            municipality.append(x['gathering']['interpretations']['municipalityDisplayname'])\n",
    "        else:\n",
    "            municipality.append(None)\n",
    "\n",
    "        # Taxon ID and Scientific Name\n",
    "        if 'unit' in x and 'linkings' in x['unit']:\n",
    "            taxonId.append(x['unit']['linkings']['taxon']['id'])\n",
    "            science.append(x['unit']['linkings']['taxon']['scientificName'])\n",
    "        else:\n",
    "            taxonId.append(None)\n",
    "            science.append(None)\n",
    "\n",
    "        # Taxon Verbatim\n",
    "        if 'unit' in x and 'taxonVerbatim' in x['unit']:\n",
    "            verbatim.append(x['unit']['taxonVerbatim'])\n",
    "        else:\n",
    "            verbatim.append(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data into a dataframe; there are a total of 115739 observations, but only 115722 rows in the dataframe. This could be due to my variables selection, e.g. there are\n",
    "# some observations that have none of the listed variables (no name, no time, no place)\n",
    "\n",
    "data = {\"date\": date, \"lat\": latitude, \"lon\": longitude, \"municipality\": municipality, \"taxonId\": taxonId, \"scientificName\": science,\n",
    "        \"verbatim\": verbatim}\n",
    "df = pd.DataFrame(data=data)\n",
    "print(df)\n",
    "df.to_csv(\"../../data/samples/tree_data_sample.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
