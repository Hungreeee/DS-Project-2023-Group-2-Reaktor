{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0xTH2aBSXYo"
      },
      "source": [
        "# Biodiversity notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq75nVge4u_a",
        "outputId": "210f1690-c7b7-4d85-ad12-1d2105275764"
      },
      "outputs": [],
      "source": [
        "!pip install ecopy\n",
        "!pip install plotly\n",
        "!pip install scikit-fda\n",
        "!pip install scipy\n",
        "!pip install gdown\n",
        "!pip install h3\n",
        "!pip install geojson"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odHZn9r4DHEJ",
        "outputId": "64179ba8-86c2-46d9-e78f-d507645f9178"
      },
      "outputs": [],
      "source": [
        "!gdown https://drive.google.com/uc?id=1QoLyZGY2DNMO_gsvg3OULfddJSLtp3Qn\n",
        "!gdown https://drive.google.com/uc?id=1oUoQD_jdq9n8-nIrmhEcP7yu0luQ_hnb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H9BTu6AjNAr"
      },
      "source": [
        "## Trees sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljmV4XWvi5iE"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.special import comb\n",
        "import scipy.misc\n",
        "scipy.misc.comb = comb\n",
        "from ecopy import diversity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kE245YWkjWvS"
      },
      "outputs": [],
      "source": [
        "# API endpoint\n",
        "URL = 'https://api.laji.fi/v0'\n",
        "# Your email\n",
        "EMAIL = 'hungmguyen13102003@gmail.com'\n",
        "# Token ID\n",
        "TOKEN = 'ffaOqj71Ro1sqR0QAVYkmOFY6vG0qDtS0ESEjvanTgsihNq69zLNMgwjIelO0zmd'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_tDqAuojcFR",
        "outputId": "59f74669-0be3-4892-8621-4cf2a33dadab"
      },
      "outputs": [],
      "source": [
        "# How to request a token\n",
        "# Just query a POST with your email. You will get the token in an email they sent you.\n",
        "response = requests.post(\n",
        "  url = URL + '/api-users',\n",
        "  data = {\n",
        "    'email': EMAIL\n",
        "  })\n",
        "\n",
        "# Check if it has been registered to the site\n",
        "responseContent = json.loads(response.content.decode('utf-8'))\n",
        "responseContent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XY_rZdcpjkBh"
      },
      "outputs": [],
      "source": [
        "# Initial request to get the last page\n",
        "response = requests.get(\n",
        "  url = URL + '/warehouse/query/unit/list',\n",
        "  params={\n",
        "    'access_token': TOKEN,\n",
        "    'page': 1,\n",
        "    'pageSize': 10000, # Limit 10,000 per page\n",
        "    'informalTaxonGroupId': 'MVL.1083', # {Vascular plants: {Plant life forms: {Trees; Evergreen trees} } }\n",
        "    'orderBy': ['gathering.eventDate.begin DESC', 'document.loadDate DESC', 'unit.taxonVerbatim ASC'] # Default sorting\n",
        "  })\n",
        "\n",
        "responseContent = response.content\n",
        "results = json.loads(responseContent.decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "w_9hOa7Sj3un",
        "outputId": "40e8613a-843b-48c4-bf0f-6c4d717cc68a"
      },
      "outputs": [],
      "source": [
        "lastPage = results['lastPage']\n",
        "\n",
        "# Lists of variables\n",
        "date = []\n",
        "latitude = []\n",
        "longitude = []\n",
        "municipality = []\n",
        "taxonId = []\n",
        "science = []\n",
        "verbatim = []\n",
        "\n",
        "for pageIndex in range(1, lastPage + 1):\n",
        "    # Request data from API and go through all the pages in the loop (approximately 8m with 12 pages and 115739 rows)\n",
        "    response = requests.get(\n",
        "        url = URL + '/warehouse/query/unit/list',\n",
        "        params={\n",
        "            'access_token': TOKEN,\n",
        "            'page': pageIndex,\n",
        "            'pageSize': 10000, # Limit 10,000 per page\n",
        "            'informalTaxonGroupId': 'MVL.1083', # {Vascular plants: {Plant life forms: {Trees; Evergreen trees} } }\n",
        "            'orderBy': ['gathering.eventDate.begin DESC', 'document.loadDate DESC', 'unit.taxonVerbatim ASC'] # Default sorting\n",
        "    })\n",
        "\n",
        "    responseContent = response.content\n",
        "    dataset = json.loads(responseContent.decode('utf-8'))['results']\n",
        "\n",
        "    # Extract relevant information, sometimes they might be missing\n",
        "    for x in dataset:\n",
        "        # Date of collection; normally it would be \"DD-MM-YYYY\", sometimes it could be a range \"DD-MM-YYY - DD-MM-YYYY\"\n",
        "        if 'displayDateTime' in x['gathering']:\n",
        "            date.append(x['gathering']['displayDateTime'])\n",
        "        else:\n",
        "            date.append(None)\n",
        "\n",
        "        # Latitude and Longitude\n",
        "        if 'conversions' in x['gathering']:\n",
        "            latitude.append(x['gathering']['conversions']['wgs84CenterPoint']['lat'])\n",
        "            longitude.append(x['gathering']['conversions']['wgs84CenterPoint']['lon'])\n",
        "        else:\n",
        "            latitude.append(None)\n",
        "            longitude.append(None)\n",
        "\n",
        "        # Municipality\n",
        "        if 'interpretations' in x['gathering']  and 'municipalityDisplayname' in x['gathering']['interpretations']:\n",
        "            municipality.append(x['gathering']['interpretations']['municipalityDisplayname'])\n",
        "        else:\n",
        "            municipality.append(None)\n",
        "\n",
        "        # Taxon ID and Scientific Name\n",
        "        if 'unit' in x and 'linkings' in x['unit']:\n",
        "            taxonId.append(x['unit']['linkings']['taxon']['id'])\n",
        "            science.append(x['unit']['linkings']['taxon']['scientificName'])\n",
        "        else:\n",
        "            taxonId.append(None)\n",
        "            science.append(None)\n",
        "\n",
        "        # Taxon Verbatim\n",
        "        if 'unit' in x and 'taxonVerbatim' in x['unit']:\n",
        "            verbatim.append(x['unit']['taxonVerbatim'])\n",
        "        else:\n",
        "            verbatim.append(None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRyEf6Kvj595"
      },
      "outputs": [],
      "source": [
        "# Merge data into a dataframe; there are a total of 115739 observations, but only 115722 rows in the dataframe. This could be due to my variables selection, e.g. there are\n",
        "# some observations that have none of the listed variables (no name, no time, no place)\n",
        "\n",
        "data = {\"date\": date, \"lat\": latitude, \"lon\": longitude, \"municipality\": municipality, \"taxonId\": taxonId, \"scientificName\": science,\n",
        "        \"verbatim\": verbatim}\n",
        "df = pd.DataFrame(data=data)\n",
        "print(df)\n",
        "df.to_csv(\"../data/samples/tree_data_sample.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vf37IZEXHXnK"
      },
      "source": [
        "# Data loading/cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Cus-TRcXkjGo",
        "outputId": "b91081ad-2d96-4633-c3ba-d2dad52c7443"
      },
      "outputs": [],
      "source": [
        "# I have uploaded the \"tree_data_sample.csv\" file to this session\n",
        "df = pd.read_csv(\"../data/samples/tree_data_sample.csv\")\n",
        "df\n",
        "\n",
        "# Another option is to download the citable file through this link https://laji.fi/en/citation/HBF.78994?locale=en\n",
        "# This table would have full variables, but somehow it only has 115295 rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urqqkYyKDn5C"
      },
      "outputs": [],
      "source": [
        "# Remove 1800s, 1900s\n",
        "df = df[~df['date'].str.startswith(('18', '19'), na=False)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04xrCbEk57Mu"
      },
      "source": [
        "## Smoothing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BxJ8hq_PNna",
        "outputId": "c6ccd125-daf0-4147-d5f9-f516f4620dfb"
      },
      "outputs": [],
      "source": [
        "#Round up latitude and longtitude to define approximate fields\n",
        "df['lat'] = df['lat'].round(1)\n",
        "df['lon'] = df['lon'].round(1)\n",
        "\n",
        "#In every location, group by lon, lat, and name to see how many of each tree type present\n",
        "groupedDf = df.groupby(['lon','lat','scientificName'])['scientificName'].count()\n",
        "groupedDf = groupedDf.rename(\"count\").reset_index()\n",
        "\n",
        "#Group counts by tree types to make smoothing separately for each type\n",
        "multiple_lists = [x for _, x in groupedDf.groupby('scientificName')]\n",
        "rolling_window = []\n",
        "\n",
        "final_df = pd.DataFrame()\n",
        "\n",
        "for i in range(0, 11):\n",
        "  #Sort values according to lon and lat to get closer points in an order\n",
        "  multiple_lists[i] = multiple_lists[i].sort_values(['lon', 'lat'])\n",
        "\n",
        "  #Remove other columns so rolling window work\n",
        "  rolling_window.append(multiple_lists[i][{'count'}])\n",
        "\n",
        "  #Rolling window with size 5 for each type\n",
        "  rolling_window[i] = rolling_window[i].rolling(window=5, closed='both').mean()\n",
        "\n",
        "  #Adding lon, lat, and name back\n",
        "  rolling_window[i]['lon'] = multiple_lists[i]['lon']\n",
        "  rolling_window[i]['lat'] = multiple_lists[i]['lat']\n",
        "  rolling_window[i]['scientificName'] = multiple_lists[i]['scientificName']\n",
        "\n",
        "  #Round zero because there can't be decimal observations\n",
        "  rolling_window[i]['count'] = rolling_window[i]['count'].round(0)\n",
        "\n",
        "  #Create the final data frame\n",
        "  final_df = final_df.append(rolling_window[i])\n",
        "\n",
        "final_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pigx2vCdGykx"
      },
      "outputs": [],
      "source": [
        "#NOT FINISHED\n",
        "\n",
        "#Calculating biodiversity indexes\n",
        "\n",
        "#Simpson's Index\n",
        "\n",
        "#Group by lon and lat, and sum count\n",
        "total_tree_df = final_df[{'lon', 'lat', 'count'}].groupby(['lon','lat'])['count'].sum().reset_index()\n",
        "\n",
        "#Loop over all elements and calculate ratio\n",
        "ratio_df = pd.DataFrame()\n",
        "for i in final_df:\n",
        "  line = total_tree_df.loc[(total_tree_df['lon'] == i[0]) & (total_tree_df['lat'] == i[1])]\n",
        "  #ratio = i[0] / line['count']\n",
        "  print((line))\n",
        "  ratio_df = ratio_df.append(pd.DataFrame([i[0], i[1], ratio]))\n",
        "\n",
        "total_tree_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-Ip73WMzzhI"
      },
      "source": [
        "## Without smoothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9D53LvTO1bBI",
        "outputId": "edf37f1a-0e29-433e-b6e7-a7d6e46930e4"
      },
      "outputs": [],
      "source": [
        "# df = pd.read_csv('data.csv')\n",
        "df = pd.read_csv(\"../data/samples/tree_data_sample.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "MFu54oEfz4QA",
        "outputId": "f84c0ae3-6185-49ac-a16c-c9c004846e64"
      },
      "outputs": [],
      "source": [
        "root_url = \"https://api.laji.fi/v0\"\n",
        "email = \"nghi.vodong942003@gmail.com\"\n",
        "access_token = \"PNQaOkSdHzJYm3zJI8PUG7OWHnmiILIOEakXPZ95gfoMEgICaGJ22IB5Hyfi5ZCT\"\n",
        "\n",
        "def extract_last_page (root_url, token, page_size):\n",
        "    response = requests.get(\n",
        "    url = root_url + '/warehouse/query/unit/list',\n",
        "    params={\n",
        "        'access_token': token,\n",
        "        'page': 1,\n",
        "        'pageSize': page_size, # Limit 10,000 per page\n",
        "        'informalTaxonGroupId': 'MVL.1083', # {Vascular plants: {Plant life forms: {Trees; Evergreen trees} } }\n",
        "        'orderBy': ['gathering.eventDate.begin DESC', 'document.loadDate DESC', 'unit.taxonVerbatim ASC'] # Default sorting\n",
        "    })\n",
        "\n",
        "    responseContent = response.content\n",
        "    results = json.loads(responseContent.decode('utf-8'))\n",
        "    lastPage = results['lastPage']\n",
        "    return lastPage\n",
        "\n",
        "lastPage = extract_last_page(root_url, access_token, 10000)\n",
        "\n",
        "features = [\n",
        "    \"gathering.displayDateTime\",\n",
        "    \"gathering.conversions.wgs84CenterPoint.lat\",\n",
        "    \"gathering.conversions.wgs84CenterPoint.lon\",\n",
        "    \"unit.linkings.taxon.id\",\n",
        "    \"unit.linkings.taxon.scientificName\",\n",
        "    \"gathering.interpretations.municipalityDisplayname\",\n",
        "    \"gathering.interpretations.finnishMunicipality\"\n",
        "]\n",
        "\n",
        "def extract_dataset (root_url, token, page_size, lastPage, features = []):\n",
        "    df = pd.DataFrame({ feature: [] for feature in features })\n",
        "    for pageIndex in range(1, lastPage + 1):\n",
        "    # Request data from API and go through all the pages in the loop (approximately 8m with 12 pages and 115739 rows)\n",
        "        response = requests.get(\n",
        "            url = root_url + '/warehouse/query/unit/list',\n",
        "            params={\n",
        "                'access_token': token,\n",
        "                'page': pageIndex,\n",
        "                'pageSize': page_size, # Limit 10,000 per page\n",
        "                'informalTaxonGroupId': 'MVL.1083', # {Vascular plants: {Plant life forms: {Trees; Evergreen trees} } }\n",
        "                'selected': features,\n",
        "                'orderBy': ['gathering.eventDate.begin DESC', 'document.loadDate DESC', 'unit.taxonVerbatim ASC'] # Default sorting\n",
        "        })\n",
        "\n",
        "        responseContent = response.content\n",
        "        dataset = json.loads(responseContent.decode('utf-8'))['results']\n",
        "        df = pd.concat([df, pd.json_normalize(dataset)])\n",
        "    return df\n",
        "\n",
        "df = extract_dataset(root_url, access_token, 10000, lastPage , features)\n",
        "df = df.rename(columns = {\n",
        "    \"gathering.displayDateTime\" : \"datetime\",\n",
        "    \"gathering.conversions.wgs84CenterPoint.lat\" : \"lat\",\n",
        "    \"gathering.conversions.wgs84CenterPoint.lon\": \"lon\",\n",
        "    \"gathering.interpretations.municipalityDisplayname\": \"municipality\",\n",
        "    \"gathering.interpretations.finnishMunicipality\" : \"municipalityId\",\n",
        "    \"unit.linkings.taxon.id\" : \"taxonId\",\n",
        "    \"unit.linkings.taxon.scientificName\" : \"scientificName\"})\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "Z89jVvjQ0d84",
        "outputId": "35ca193d-dc1f-46d0-a84b-540a1a2c5c89"
      },
      "outputs": [],
      "source": [
        "def group_observations (dataframe, columns):\n",
        "    grouped_df = dataframe.groupby(columns).count()\n",
        "    grouped_df.reset_index(inplace = True)\n",
        "    columns_to_drop = list(filter(lambda name : name not in columns, grouped_df.columns))\n",
        "    grouped_df = grouped_df.drop(columns = columns_to_drop[1:])\n",
        "    grouped_df.columns = columns + [\"nof_obs\"]\n",
        "    return grouped_df\n",
        "\n",
        "# scientificName or taxonId works\n",
        "grouped_df = group_observations(df, ['municipalityId', 'scientificName'])\n",
        "#grouped_df.to_csv('grouped_municipality.csv')\n",
        "\n",
        "def pivot_obs_dataframe (dataframe, species_identifier, area_id):\n",
        "    pivoted_df = dataframe.pivot(index = area_id, columns = species_identifier, values = \"nof_obs\")\n",
        "    pivoted_df = pivoted_df.fillna(0.0)\n",
        "    return pivoted_df\n",
        "\n",
        "\n",
        "pivoted_df = pivot_obs_dataframe(grouped_df, \"scientificName\", \"municipalityId\")\n",
        "#pivoted_df.to_csv('pivoted_municipality.csv')\n",
        "pivoted_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pLatUdxvdHO",
        "outputId": "641cef72-f193-40df-c7ea-a1dd0755024a"
      },
      "outputs": [],
      "source": [
        "def shannon_entropy (area_row):\n",
        "    numpy_row = area_row.to_numpy()\n",
        "    probabilities = numpy_row / np.sum(numpy_row)\n",
        "    probabilities = probabilities[np.where(probabilities > 0)]\n",
        "    return -np.sum(probabilities*np.log2(probabilities))\n",
        "\n",
        "shannon_entropies = pivoted_df.apply(shannon_entropy, axis=1)\n",
        "shannon_entropies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5V04QYTyvqyD",
        "outputId": "d60b42a7-5ce2-4013-ac4a-b94ab52f6123"
      },
      "outputs": [],
      "source": [
        "def simpson_index (area_row):\n",
        "    numpy_row = area_row.to_numpy()\n",
        "    observed_species = numpy_row[np.where(numpy_row > 0.0)]\n",
        "    species_index = observed_species * (observed_species - 1)\n",
        "    total_observations = np.sum(observed_species)\n",
        "    total_index = total_observations * (total_observations - 1)\n",
        "    return 1 - (np.sum(species_index) / total_index)\n",
        "\n",
        "simpson_indices = pivoted_df.apply(simpson_index, axis=1)\n",
        "simpson_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "wOTLrLKmvyiT",
        "outputId": "5eecfed7-6f6b-4193-ce5d-9e0ca9468285"
      },
      "outputs": [],
      "source": [
        "root_url = \"https://api.laji.fi/v0\"\n",
        "email = \"nghi.vodong942003@gmail.com\"\n",
        "access_token = \"PNQaOkSdHzJYm3zJI8PUG7OWHnmiILIOEakXPZ95gfoMEgICaGJ22IB5Hyfi5ZCT\"\n",
        "\n",
        "def request_areas_info (municipality_ids, root_url, token):\n",
        "    assert len(municipality_ids) > 0\n",
        "    cleaned_ids = [id for id in municipality_ids if str(id) != \"nan\"]\n",
        "    unique_ids = list(set(cleaned_ids))\n",
        "    unique_ids.sort()\n",
        "    area_endpoint_url = root_url + \"/areas\"\n",
        "    ids_string = \"\"\n",
        "    nof_ids = len(unique_ids)\n",
        "    intervals = 1.0 * len(unique_ids) / 10\n",
        "    current_interval = 0\n",
        "    dataset = []\n",
        "    while current_interval < intervals:\n",
        "        ids_string = \"\"\n",
        "        ids_slice = unique_ids[current_interval*10 : min(current_interval*10 + 10, nof_ids)]\n",
        "        for municipality_id in ids_slice:\n",
        "            ids_string += \",\" + municipality_id\n",
        "        ids_string = ids_string[1:]\n",
        "        response = requests.get(\n",
        "            url = area_endpoint_url,\n",
        "            params={\n",
        "                'access_token': token,\n",
        "                'page': 1,\n",
        "                'pageSize': 10,\n",
        "                'idIn' : ids_string,\n",
        "        })\n",
        "        dataset.extend(json.loads(response.content.decode('utf-8'))['results'])\n",
        "        current_interval += 1\n",
        "    df = pd.json_normalize(dataset)\n",
        "    df.rename({'id' : 'municipalityId'}, inplace = True)\n",
        "    return df\n",
        "municipality_info_df = request_areas_info (\n",
        "    list(df[\"municipalityId\"]), root_url, access_token\n",
        ")\n",
        "municipality_info_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5PMDOxf4FRH"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RrreZrJ4oFE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.figure_factory as ff\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Polygon\n",
        "import h3\n",
        "import s2\n",
        "from geojson import Feature, Point, FeatureCollection\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tQoE61khGqNx",
        "outputId": "0b85bd2c-384c-4609-fbc8-38dcbcf62ee1"
      },
      "outputs": [],
      "source": [
        "df_vis = df.copy()\n",
        "df_vis.dropna(subset=['lat', 'lon'], inplace=True)\n",
        "df_vis.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyWbl_jL1qCk"
      },
      "outputs": [],
      "source": [
        "df_vis['municipality'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "xBuHzHDUTlAc",
        "outputId": "fe158c68-9614-4950-8e3d-ac4a6a1a3da8"
      },
      "outputs": [],
      "source": [
        "def geo_to_h3(row):\n",
        "  return h3.geo_to_h3(lat=row['lat'], lng=row['lon'], resolution = 5)\n",
        "\n",
        "df_vis['h3_cell'] = df_vis.apply(geo_to_h3, axis=1)\n",
        "df_vis_ag = df_vis.reset_index(drop=False)\n",
        "df_vis_ag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "biCqYSDUbrB1",
        "outputId": "76463d08-894f-4eea-d9c1-73b496f66510"
      },
      "outputs": [],
      "source": [
        "df_vis_agg = (df_vis_ag\n",
        "              .groupby('h3_cell')\n",
        "              .index\n",
        "              .agg(list)\n",
        "              .to_frame(\"ids\")\n",
        "              .reset_index())\n",
        "\n",
        "df_vis_agg['count'] = df_vis_agg['ids'].apply(lambda row: len(row))\n",
        "df_vis_agg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "nulDXVCGUX10",
        "outputId": "21addc29-5183-4ae6-e80f-3c463dd208a6"
      },
      "outputs": [],
      "source": [
        "def add_geometry(row):\n",
        "  points = h3.h3_to_geo_boundary(row['h3_cell'], True)\n",
        "  return Polygon(points)\n",
        "\n",
        "df_vis_agg['geometry'] = df_vis_agg.apply(add_geometry,axis=1)\n",
        "df_vis_agg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Beu5ey5XYpn"
      },
      "outputs": [],
      "source": [
        "def hex_to_geojson(df_hex, hex_id_field, geometry_field, value_field):\n",
        "  list_features = []\n",
        "  for i, row in df_hex.iterrows():\n",
        "    feature = Feature(geometry=row[geometry_field],\n",
        "                      id=row[hex_id_field],\n",
        "                      properties={'value': row[value_field]})\n",
        "    list_features.append(feature)\n",
        "    feat_collection = FeatureCollection(list_features)\n",
        "  return feat_collection\n",
        "\n",
        "geojson_obj = hex_to_geojson(df_vis_agg, hex_id_field='h3_cell', value_field='count', geometry_field='geometry')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "6mFSqAOg-AqI",
        "outputId": "f189306a-43d8-4b64-ae16-f3a3c83ebd24"
      },
      "outputs": [],
      "source": [
        "def plot_observation_count(data: pd.DataFrame, category: str = 'all'):\n",
        "  if category != 'all':\n",
        "    data = data[data['scientificName'] == category]\n",
        "\n",
        "  month_count = data['date'].apply(lambda row: row[:7] if isinstance(row, str) else None).value_counts().sort_index()\n",
        "  fig = px.line(x=month_count.index, y=month_count.values)\n",
        "  fig.update_layout(title=f'Observations count for {category}',\n",
        "                    xaxis_title='Month',\n",
        "                    yaxis_title='Observations')\n",
        "  fig.show()\n",
        "\n",
        "plot_observation_count(df_vis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "FgXM_MyX2-OV",
        "outputId": "b6e5a0ff-5e8f-48ec-bf7f-8d98f833d0c5"
      },
      "outputs": [],
      "source": [
        "def plot_observation_municipality(data: pd.DataFrame, category: str = 'all'):\n",
        "  if category != 'all':\n",
        "    data = data[data['scientificName'] == category]\n",
        "\n",
        "  mun_count = data['municipality'].value_counts().head(10)\n",
        "  fig = px.bar(x=mun_count.index, y=mun_count.values)\n",
        "  fig.update_layout(title=f'Top 10 municipality for {category}',\n",
        "                    xaxis_title='Municipality',\n",
        "                    yaxis_title='Observations')\n",
        "  fig.show()\n",
        "\n",
        "plot_observation_municipality(df_vis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "L88siHN7-DnK",
        "outputId": "ae1ef580-72dc-4543-a4a1-2e2101146d27"
      },
      "outputs": [],
      "source": [
        "def plot_observation_comp(data: pd.DataFrame):\n",
        "  obs_count = data['scientificName'].value_counts().to_frame().reset_index()\n",
        "  obs_count.columns = ['scientificName', 'count']\n",
        "  obs_count_small = obs_count[obs_count['count'] < 250].sum().to_frame().T\n",
        "  obs_count_small.loc[0, 'scientificName'] = 'Others'\n",
        "  obs_count_agg = pd.concat([obs_count_small, obs_count[obs_count['count'] >= 250]])\n",
        "  fig = px.pie(obs_count_agg, values='count', names='scientificName')\n",
        "  fig.update_layout(title=f'Distributions of composing species')\n",
        "  fig.show()\n",
        "\n",
        "plot_observation_comp(df_vis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "pG2M6VkERsRp",
        "outputId": "97d435c0-2dc8-435a-ea46-ef0378eabbe8"
      },
      "outputs": [],
      "source": [
        "def discrete_colorscale(bvals, colors):\n",
        "    \"\"\"\n",
        "    bvals - list of values bounding intervals/ranges of interest\n",
        "    colors - list of rgb or hex color codes for values in [bvals[k], bvals[k+1]],0<=k < len(bvals)-1\n",
        "    returns a nonuniform discrete colorscale\n",
        "    \"\"\"\n",
        "    if len(bvals) != len(colors)+1:\n",
        "        raise ValueError('len(boundary values) should be equal to  len(colors)+1')\n",
        "    bvals = sorted(bvals)\n",
        "    nvals = [(v-bvals[0])/(bvals[-1]-bvals[0]) for v in bvals]  #normalized values\n",
        "\n",
        "    dcolorscale = [] #discrete colorscale\n",
        "    for k in range(len(colors)):\n",
        "        dcolorscale.extend([[nvals[k], colors[k]], [nvals[k+1], colors[k]]])\n",
        "    return dcolorscale\n",
        "\n",
        "bvals= [1, 10, 100, 1000]\n",
        "colors=[\"#e62bf0\", \"#2026e3\", \"#26de26\"]\n",
        "discrete_nonuniform = discrete_colorscale(bvals, colors)\n",
        "\n",
        "bvals = np.array(bvals)\n",
        "tickvals = [np.mean(bvals[k:k+2]) for k in range(len(bvals)-1)]\n",
        "ticktext =  [f'{bvals[k]}-' for k in range(0, len(bvals)-1)]\n",
        "\n",
        "fig = px.choropleth_mapbox(\n",
        "    df_vis_agg,\n",
        "    geojson=geojson_obj,\n",
        "    color_continuous_scale=discrete_nonuniform,\n",
        "    locations='h3_cell',\n",
        "    color='count',\n",
        "    center=dict(lat=65, lon=24),\n",
        "    zoom=4.3,\n",
        "    width=600,\n",
        "    height=650,\n",
        "    opacity=0.3,\n",
        "    labels={'count': 'observations'},\n",
        "    mapbox_style=\"open-street-map\")\n",
        "\n",
        "fig.update_geos(projection_type='foucaut')\n",
        "\n",
        "fig.update_layout(\n",
        "      autosize=False,\n",
        "      margin = dict(l=0, r=0, b=0, t=0, pad=4, autoexpand=True),\n",
        "      coloraxis =dict(colorbar_thickness=25, colorbar_ticktext=ticktext, colorbar_tickvals=tickvals)\n",
        "    )\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eSLwL3nwt8r"
      },
      "source": [
        "### Gridding (& smoothing?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klQspfxI1Qxu"
      },
      "source": [
        "See here https://colab.research.google.com/drive/1scpAh0uaBH99KI2Q2yxG4D7pU3Tbg0F-#scrollTo=yJcezMMwzWlH"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
